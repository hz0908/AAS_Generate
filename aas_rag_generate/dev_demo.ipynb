{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from prompt_info import PromptInfo\n",
    "from import_seg import import_seg_prompt\n",
    "from semantic_seg import semantic_seg_prompt\n",
    "from task_seg import task_seg_prompt\n",
    "import torch\n",
    "import json\n",
    "print(task_seg_prompt.answer_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptInfo1:\n",
    "    def __init__(self, system=\"你是一个优秀的人工智能\" , que_1=\"问题示例1\", answer_1=\"答案1\", que_2=\"问题示例2 \", answer_2=\"答案2\"):\n",
    "        # 大模型的角色定位描述\n",
    "        self.system = system\n",
    "        # 示例 1 的输入\n",
    "        self.que_1 = que_1\n",
    "        # 示例 1 的输出\n",
    "        self.answer_1 = answer_1\n",
    "        # 示例 2 的输入\n",
    "        self.que_2 = que_2\n",
    "        # 示例 2 的输出\n",
    "        self.answer_2 = answer_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro=PromptInfo1(\"nishish\")\n",
    "print(pro.system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "#model_path = \"/home/imc/桌面/Qwen1.5-72B/pythonProject/model/LLM-Research/Meta-Llama-3-8B-Instruct\"\n",
    "#model_path = \"/home/imc/桌面/aas_rag_generate/Qwen/Qwen2-7B\"\n",
    "model_path = \"/home/imc/桌面/Qwen1.5-72B/pythonProject/model/qwen/Qwen1___5-14B-Chat\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(text):\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "    input_ids = tokenizer.encode(text,return_tensors='pt')\n",
    "    attention_mask = torch.ones(input_ids.shape,dtype=torch.long,device=device)\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare your prompts\n",
    "prompt = \"scara机械臂将水瓶夹起放置在传送带上，经传送带运输到delata机器人前\"\n",
    "print(semantic_seg_prompt.system)\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": semantic_seg_prompt.system},\n",
    "    {\"role\": \"user\", \"content\": semantic_seg_prompt.que_1},\n",
    "    {\"role\": \"assistant\", \"content\": semantic_seg_prompt.answer_1},\n",
    "    {\"role\": \"user\", \"content\": semantic_seg_prompt.que_2},\n",
    "    {\"role\": \"assistant\", \"content\": semantic_seg_prompt.answer_2},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "\n",
    "]\n",
    "semantic_seg_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(semantic_seg_text)\n",
    "\n",
    "# response = generate_response(text=semantic_seg_text)\n",
    "# #print(response)\n",
    "\n",
    "# data = json.loads(response)\n",
    "\n",
    "# print(data)\n",
    "\n",
    "with open(\"./semantic_result_demo.json\", 'r') as file:\n",
    "    equipment_required_data = json.load(file)\n",
    "\n",
    "print(equipment_required_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_asset_name(equipment_name,aas_data):\n",
    "    #to do\n",
    "    return equipment_name\n",
    "\n",
    "def get_digital_twin_submodle_byname(asset_name,aas_json):\n",
    "    for asset_item in aas_json:\n",
    "        if(asset_item[\"assetName\"]==asset_name):\n",
    "            return asset_item    \n",
    "    return {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载aas模型json文件\n",
    "with open(\"./aas_model.json\", 'r') as file:\n",
    "    aas_data = json.load(file)\n",
    "    print(aas_data)\n",
    "equipment_info = equipment_required_data[\"equipmentInfo\"]\n",
    "#print(equipment_info)\n",
    "\n",
    "#根据equipment name匹配asset，增加json字段，后续要多次使用\n",
    "for item in equipment_info:\n",
    "    equipment_name = item[\"equipmentName\"]\n",
    "    asset_name = get_matched_asset_name(equipment_name,aas_data)\n",
    "    item[\"aas_sub_model\"] = get_digital_twin_submodle_byname(asset_name, aas_data)\n",
    "    item[\"asset_name\"] = asset_name \n",
    "    for istance in item[\"instanceEquipment\"]:\n",
    "        istance[\"aas_sub_model\"] = item[\"aas_sub_model\"]\n",
    "        istance[\"asset_name\"] = asset_name\n",
    "        print(istance)\n",
    "    print(item)\n",
    "\n",
    "print(get_digital_twin_submodle_byname(\"jetbot 小车\",aas_data))\n",
    "print(\"jetbot小车\")\n",
    "# item[\"aas_model\"]='''    {\n",
    "#         \"assetName\":\"jetbot 小车\",\n",
    "#         \"assetDescription\":\"一个用于移动的智能小车\",\n",
    "#         \"libRelyOn\":[\"lib3\"],\n",
    "#         \"initSeg\":\"init_jetbot\",\n",
    "#         \"resetSeg\":\"reset_jetbot\",\n",
    "#         \"physicsSeg\":\"physics_jetbot\"\n",
    "#     }\n",
    "# '''\n",
    "\n",
    "# 遍历每一个equipment中的equipmentName字段\n",
    "\n",
    "# 此部分代码根据json文本的描述，生成相应的init段等的代码\n",
    "\n",
    "# 查询 根据每种equipment的描述词，查询出aas模型资料库中对应的字段信息\n",
    "\n",
    "\n",
    "# 查询到字段，输出相应的import、 init、 reset等段提示词信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import段的操作\n",
    "# Prepare your prompts\n",
    "import_seg_user_input=\" \"\n",
    "for item in equipment_info:\n",
    "    print(item)\n",
    "    asset_name = item[\"asset_name\"]\n",
    "    import_seg_user_input += item[\"aas_sub_model\"][\"importSeg\"]\n",
    "\n",
    "print(import_seg_user_input)\n",
    "\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": import_seg_prompt.system},\n",
    "    {\"role\": \"user\", \"content\": import_seg_prompt.que_1},\n",
    "    {\"role\": \"assistant\", \"content\": import_seg_prompt.answer_1},\n",
    "    {\"role\": \"user\", \"content\": import_seg_prompt.que_2},\n",
    "    {\"role\": \"assistant\", \"content\": import_seg_prompt.answer_2},\n",
    "    {\"role\": \"user\", \"content\": import_seg_user_input}\n",
    "\n",
    "]\n",
    "import_seg_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "print(import_seg_text)\n",
    "\n",
    "import_seg_output = generate_response(import_seg_text)\n",
    "print(import_seg_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init seg\n",
    "\n",
    "##定位\n",
    "init_seg_system = \"你是一名高级的python工程师，能够根据需求和经验写出正确的代码片段\"\n",
    "\n",
    "init_seg_text = []\n",
    "\n",
    "## 模板\n",
    "init_seg_user_input_template = \"请你写出将{object}放在{location}并初始化的代码，变量名请使用{variable_name}或以{variable_name}作为前缀\"\n",
    "\n",
    "# 使用 format 方法替换占位符\n",
    "object_name = \"方块\"\n",
    "location = \"桌子上\"\n",
    "variable_name = \"block\"\n",
    "prefix = \"block_\"\n",
    "\n",
    "\n",
    "formatted_input = init_seg_user_input_template.format(object=object_name, location=location, variable_name=variable_name)\n",
    "print(formatted_input)\n",
    "\n",
    "for item in equipment_info :\n",
    "    for instance in item[\"instanceEquipment\"] :\n",
    "        init_seg_user_input = init_seg_user_input_template.format(object=instance[\"asset_name\"], location=instance[\"position\"], variable_name=instance[\"programName\"])\n",
    "        print(init_seg_user_input)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": init_seg_system},\n",
    "            {\"role\": \"user\", \"content\": instance[\"aas_sub_model\"][\"initSeg\"][\"initDescription\"]},\n",
    "            {\"role\": \"assistant\", \"content\": instance[\"aas_sub_model\"][\"initSeg\"][\"initCode\"]},\n",
    "            {\"role\": \"user\", \"content\": init_seg_user_input}\n",
    "        ]\n",
    "        init_seg_text_temp = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        init_seg_text.append(init_seg_text_temp)\n",
    "\n",
    "\n",
    "print(init_seg_text)\n",
    "\n",
    "init_seg_output = []\n",
    "# for text in init_seg_text :\n",
    "#     init_seg_output.append(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset seg\n",
    "# reset seg\n",
    "\n",
    "##定位\n",
    "reset_seg_system = \"你是一名高级的python工程师，能够根据需求和经验写出正确的代码片段\"\n",
    "\n",
    "reset_seg_text = []\n",
    "\n",
    "## 模板\n",
    "reset_seg_user_input_template = \"请你写出{object}的reset代码，变量名请使用{variable_name}或以{variable_name}作为前缀\"\n",
    "\n",
    "\n",
    "\n",
    "for item in equipment_info :\n",
    "    for instance in item[\"instanceEquipment\"] :\n",
    "        reset_seg_user_input = reset_seg_user_input_template.format(object=instance[\"asset_name\"], variable_name=instance[\"programName\"])\n",
    "        print(reset_seg_user_input)\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": reset_seg_system},\n",
    "            {\"role\": \"user\", \"content\": instance[\"aas_sub_model\"][\"resetSeg\"][\"resetDescription\"]},\n",
    "            {\"role\": \"assistant\", \"content\": instance[\"aas_sub_model\"][\"resetSeg\"][\"resetCode\"]},\n",
    "            {\"role\": \"user\", \"content\": reset_seg_user_input}\n",
    "        ]\n",
    "        reset_seg_text_temp = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        reset_seg_text.append(reset_seg_text_temp)\n",
    "\n",
    "\n",
    "print(reset_seg_text)\n",
    "\n",
    "reset_seg_output = []\n",
    "# for text in reset_seg_text :\n",
    "#     reset_seg_output.append(generate_response(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_instance_by_description(description, equipment_info_json) :\n",
    "    for item in equipment_info_json :\n",
    "        for instance in item[\"instanceEquipment\"] :\n",
    "            if instance[\"descriptionName\"]==description :\n",
    "                return instance\n",
    "            \n",
    "    return {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#任务切分\n",
    "# Prepare your prompts\n",
    "task_seg_user_input=\"franka机械臂抓起一个物块A放到jetbot小车上，ur10机械臂将物块A抓起放到另一个位置 \" #后边看看要不要处理一下吧\n",
    "\n",
    "# print(task_seg_user_input)\n",
    "\n",
    "# print(task_seg_prompt.answer_1)\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": task_seg_prompt.system},\n",
    "    {\"role\": \"user\", \"content\": task_seg_prompt.que_1},\n",
    "    {\"role\": \"assistant\", \"content\": task_seg_prompt.answer_1},\n",
    "    {\"role\": \"user\", \"content\": task_seg_prompt.que_2},\n",
    "    {\"role\": \"assistant\", \"content\": task_seg_prompt.answer_2},\n",
    "    {\"role\": \"user\", \"content\": task_seg_user_input}\n",
    "]\n",
    "task_seg_text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "\n",
    "# print(task_seg_text)\n",
    "\n",
    "task_seg_output = generate_response(task_seg_text)\n",
    "print(task_seg_output)\n",
    "\n",
    "task_seg_json = json.loads(task_seg_output)\n",
    "print(task_seg_json[\"task_count\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matched_physcis_seg_by_task_description(task_description, asset_used) :\n",
    "    # to do \n",
    "    return asset_used[0][\"instance\"][\"aas_sub_model\"][\"physicsSeg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phy_seg_que_template(task_description,variable_list):\n",
    "    template = \"请你写出{}的Python代码片段，其中{}\"\n",
    "    variable_names = \", \".join([f\"{var_name}使用变量名{var}\" for var_name, var in variable_list])\n",
    "    init_seg_user_input = template.format(task_description, variable_names)\n",
    "    return init_seg_user_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_set = task_seg_json[\"task_set\"]\n",
    "for task in task_set :\n",
    "    for asset in task[\"asset_used\"] :\n",
    "        asset[\"instance\"] = get_matched_instance_by_description(asset[\"user_description\"],equipment_info)\n",
    "\n",
    "print(task_seg_json)\n",
    "\n",
    "phy_seg_prompt_system = \"你是一个高级pyhton工程师，能够学习历史对话中的示例，写出符合用户输入需求的python程序片段\"\n",
    "phy_seg_text = []\n",
    "# 模板\n",
    "phy_seg_user_input_template = \"请你写出{object}的python代码片段，其中变量名请使用{variable_name}或以{variable_name}作为前缀\"\n",
    "\n",
    "for task in task_set :\n",
    "    task_number = task[\"task_number\"]\n",
    "    phy_seg_reference = get_matched_physcis_seg_by_task_description(task[\"task_description\"],task[\"asset_used\"])\n",
    "    print(phy_seg_reference)\n",
    "    phy_template_variables = []\n",
    "    for asset in task[\"asset_used\"] :\n",
    "        phy_template_variables.append((asset[\"user_description\"],asset[\"instance\"][\"programName\"]))\n",
    "\n",
    "    phy_seg_user_input = generate_phy_seg_que_template(task[\"task_description\"],phy_template_variables)\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": phy_seg_prompt_system},\n",
    "    {\"role\": \"user\", \"content\": phy_seg_reference[\"physicsDescription\"]},\n",
    "    {\"role\": \"assistant\", \"content\": phy_seg_reference[\"physicsCode\"]},\n",
    "    {\"role\": \"user\", \"content\": phy_seg_user_input},\n",
    "    ]\n",
    "    phy_seg_text_temp = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    "    )\n",
    "    phy_seg_text.append(phy_seg_text_temp)\n",
    "\n",
    "print(phy_seg_text[1])\n",
    "phy_seg_output = []\n",
    "\n",
    "# for text in phy_seg_text :\n",
    "#     phy_seg_output.append(generate_response(text))\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将代码拼接起来"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
